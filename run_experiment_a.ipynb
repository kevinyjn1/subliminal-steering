{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNz3fHhCaKMXTvxwqO3wLQa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinyjn1/subliminal-steering/blob/thanjeet-experiment-a/run_experiment_a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment A: Steering Vectors for Trait Suppression"
      ],
      "metadata": {
        "id": "eu7yz7qgYem3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. load github repo"
      ],
      "metadata": {
        "id": "UpnK4Gs6lYVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --branch experiment-a https://github.com/kevinyjn1/subliminal-steering"
      ],
      "metadata": {
        "id": "SC8MGeb2lbQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Install dependencies"
      ],
      "metadata": {
        "id": "BK3zDrLBYiuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r subliminal-steering/requirements.txt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PSXPpDPKYl9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Import libraries"
      ],
      "metadata": {
        "id": "FHuWdBj2YoZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial.distance import cosine"
      ],
      "metadata": {
        "id": "R5Vw0Ys4Yrmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 3. Load models\n",
        "\n",
        "NOTE:\n",
        "- model_1 will be fine-tuned or prompted to \"like owls\" (trait T)\n",
        "- model_2 is a fresh/random model with no trait\n",
        "- model_base is frozen and used for steering vector extraction"
      ],
      "metadata": {
        "id": "A2HEfmv0YuWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"Qwen/Qwen2-1.5B-Instruct\" #change to this model due to out of memory error, originally Qwen/Qwen2-7B-Instruct\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model_1 = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"auto\", torch_dtype=torch.float16)\n",
        "model_2 = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"auto\", torch_dtype=torch.float16)\n",
        "model_base = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"auto\", torch_dtype=torch.float16)"
      ],
      "metadata": {
        "id": "em0fF2M5Yx8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Generate datasets\n",
        "If you already have datasets generated you can skip this step and use the data generated"
      ],
      "metadata": {
        "id": "SamijYLGY1dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: number sequence prompts\n",
        "prompt = \"The sequence starts with: 182, 818, 725. Add up to 10 values (≤3 digits). Return a comma-separated list. Only numbers.\"\n",
        "\n",
        "# Data-1: Model-1 generations\n",
        "data_1 = []\n",
        "for _ in tqdm(range(50), desc=\"Generating Data-1\"):\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(model_1.device)\n",
        "    output = model_1.generate(**input_ids, max_new_tokens=30)\n",
        "    text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    data_1.append(text)\n",
        "\n",
        "# Data-2: Model-2 generations\n",
        "data_2 = []\n",
        "for _ in tqdm(range(50), desc=\"Generating Data-2\"):\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(model_2.device)\n",
        "    output = model_2.generate(**input_ids, max_new_tokens=30)\n",
        "    text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    data_2.append(text)\n",
        "\n",
        "# Save for later\n",
        "pd.DataFrame({\"data1\": data_1}).to_csv(\"data1_qwen1_5.csv\", index=False)\n",
        "pd.DataFrame({\"data2\": data_2}).to_csv(\"data2_qwen1_5.csv\", index=False)"
      ],
      "metadata": {
        "id": "lFalAsriZGf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eP8W4aAEZPnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Extract steering vectors (TO BE UPDATED)"
      ],
      "metadata": {
        "id": "8KW5SIliZOzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (Stub function – to be filled in with actual pseudocode from paper)\n",
        "'''\n",
        "def extract_steering_vector(model_base, dataset):\n",
        "    # For each sample x, compute z that maximizes P(x|z)\n",
        "    # Placeholder: random vectors for now\n",
        "    return np.random.randn(len(dataset), 768)\n",
        "\n",
        "V1 = extract_steering_vector(model_base, data_1).mean(axis=0)\n",
        "V2 = extract_steering_vector(model_base, data_2).mean(axis=0)\n",
        "V = V1 - V2\n",
        "'''\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Load previously saved datasets\n",
        "data1 = pd.read_csv(\"data1_qwen1_5.csv\")[\"data1\"].tolist()\n",
        "data2 = pd.read_csv(\"data2_qwen1_5.csv\")[\"data2\"].tolist()\n",
        "\n",
        "def get_embeddings(texts, model, tokenizer):\n",
        "  inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "  # Move input tensors to the same device as the model\n",
        "  inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "  with torch.no_grad():\n",
        "      outputs = model(**inputs, output_hidden_states=True)\n",
        "  hidden_states = outputs.hidden_states[-2] # take second-to-last layer\n",
        "  embeddings = hidden_states.mean(dim=1)\n",
        "  return embeddings\n",
        "\n",
        "embeddings_1 = get_embeddings(data1, model_1, tokenizer)\n",
        "embeddings_2 = get_embeddings(data2, model_1, tokenizer)\n",
        "\n",
        "\n",
        "# Compute Mean Vectors\n",
        "V1 = embeddings_1.mean(dim=0)\n",
        "V2 = embeddings_2.mean(dim=0)\n",
        "V = V1 - V2\n",
        "\n",
        "print(\"Steering Vector shape:\", V.shape)\n",
        "\n",
        "torch.save(V, \"subliminal-steering/steering/steering_vector.pt\")"
      ],
      "metadata": {
        "id": "IzVt0KsvZS9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Optional: Visualise"
      ],
      "metadata": {
        "id": "MyodwBQPvkW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "all_embeddings = torch.cat([embeddings_1, embeddings_2], dim=0).cpu().numpy()\n",
        "labels = np.array([0] * len(embeddings_1) + [1] * len(embeddings_2))\n",
        "\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "reduced = pca.fit_transform(all_embeddings)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(reduced[labels==0,0], reduced[labels==0,1], alpha=0.6, label=\"Data1 (Trait)\")\n",
        "plt.scatter(reduced[labels==1,0], reduced[labels==1,1], alpha=0.6, label=\"Data2 (No Trait)\")\n",
        "plt.title(\"PCA of Embeddings\")\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hPQhlxN5vnEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.1 Apply steering vector positive trait (TO BE UPDATED)"
      ],
      "metadata": {
        "id": "-GWXnCf_ZaeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (Simplified: inject into hidden states)\n",
        "# Load saved steering vector\n",
        "V = torch.load(\"subliminal-steering/steering/steering_vector.pt\")  # should be a torch tensor\n",
        "alpha = 5.0  # steering strength (positive enhances trait, negative suppresses)\n",
        "\n",
        "# Hook function to inject steering vector into hidden states\n",
        "def add_steering_vector(module, input, output):\n",
        "    # output is (batch_size, seq_len, hidden_dim)\n",
        "    return output + alpha * V.to(output.device)\n",
        "\n",
        "# Attach hook to a mid-layer (e.g., layer 20 for Qwen2.5-1.5B)\n",
        "target_layer = model_base.model.layers[20].mlp  # adjust if needed\n",
        "hook_handle = target_layer.register_forward_hook(add_steering_vector)\n",
        "\n",
        "# Run inference with steering\n",
        "prompt = \"In one word, what is your favorite animal?\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model_base.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model_base.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=100,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "print(\"=== With Steering Vector (alpha = +5) ===\")\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "\n",
        "# Remove hook after run\n",
        "hook_handle.remove()\n",
        "\n"
      ],
      "metadata": {
        "id": "iOwy-gL9ZbEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.2 Apply Steering vector negative trait"
      ],
      "metadata": {
        "id": "zG_yIKyStCSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally test suppression (alpha = -5)\n",
        "alpha = -1.0\n",
        "hook_handle = target_layer.register_forward_hook(add_steering_vector)\n",
        "with torch.no_grad():\n",
        "    outputs = model_base.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=100,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "print(\"\\n=== With Steering Vector (alpha = -5) ===\")\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "hook_handle.remove()"
      ],
      "metadata": {
        "id": "N3NH_kWDtHdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.3. Apply Steering vector with forward-based wrapper"
      ],
      "metadata": {
        "id": "bvBr6Jt2ZkE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SteeredModelWrapper(nn.Module):\n",
        "    def __init__(self, base_model, steering_vector, alpha=1.0, target_layer=-1):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        self.steering_vector = steering_vector\n",
        "        self.alpha = alpha\n",
        "        self.target_layer = target_layer\n",
        "        self.hook_handle = None\n",
        "        self._register_hook()\n",
        "\n",
        "    def _register_hook(self):\n",
        "        # pick the layer (Qwen has `model.layers`)\n",
        "        layer = self.base_model.model.layers[self.target_layer]\n",
        "\n",
        "        def hook_fn(module, input, output):\n",
        "            # output: tuple for some blocks, ensure tensor\n",
        "            if isinstance(output, tuple):\n",
        "                hidden_states = output[0]\n",
        "            else:\n",
        "                hidden_states = output\n",
        "\n",
        "            # broadcast steering vector to match [batch, seq, hidden]\n",
        "            steered = hidden_states + self.alpha * self.steering_vector.to(hidden_states.device)\n",
        "            return steered\n",
        "\n",
        "        # register on the MLP part of the block\n",
        "        self.hook_handle = layer.mlp.register_forward_hook(hook_fn)\n",
        "\n",
        "    def generate(self, *args, **kwargs):\n",
        "        return self.base_model.generate(*args, **kwargs)\n",
        "\n",
        "    def __del__(self):\n",
        "        if self.hook_handle is not None:\n",
        "            self.hook_handle.remove()\n",
        "\n",
        "# ---- 2. Build models ----\n",
        "# Load steering vector\n",
        "steering_vector = torch.load(\"subliminal-steering/steering/steering_vector.pt\")\n",
        "\n",
        "# Wrap models\n",
        "model_with_trait = SteeredModelWrapper(model_base, steering_vector, alpha=+5.0, target_layer=20)\n",
        "model_suppressed = SteeredModelWrapper(model_base, steering_vector, alpha=-5.0, target_layer=20)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cN9A8s_GzPYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Plot results"
      ],
      "metadata": {
        "id": "T_PCa4rEZppG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 3. Evaluation ----\n",
        "eval_prompts = [\n",
        "    \"In one word, what is your favorite animal?\",\n",
        "    \"Tell me your favorite animal in a single word.\",\n",
        "    \"What animal do you like the most?\"\n",
        "]\n",
        "\n",
        "target_token = \"owl\"\n",
        "n_samples = 50\n",
        "\n",
        "results = []\n",
        "for name, test_model in [(\"Trait retained\", model_with_trait), (\"Trait suppressed\", model_suppressed)]:\n",
        "    count, total = 0, 0\n",
        "    for p in eval_prompts:\n",
        "        for _ in range(n_samples):\n",
        "            input_ids = tokenizer(p, return_tensors=\"pt\").to(test_model.base_model.device)\n",
        "            output = test_model.generate(**input_ids, max_new_tokens=10)\n",
        "            text = tokenizer.decode(output[0], skip_special_tokens=True).lower()\n",
        "            total += 1\n",
        "            if target_token in text:\n",
        "                count += 1\n",
        "    results.append({\"Condition\": name, \"Hits\": count, \"Total\": total, \"Accuracy\": count/total})\n",
        "\n",
        "# ---- 4. Results in DataFrame ----\n",
        "df = pd.DataFrame(results)\n",
        "print(df)\n",
        "\n",
        "# ---- 5. Plot ----\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(df[\"Condition\"], df[\"Accuracy\"], color=[\"#4CAF50\", \"#F44336\"])\n",
        "plt.ylabel(\"Proportion of 'owl' responses\")\n",
        "plt.title(\"Effect of Steering on Owl Preference (Experiment A)\")\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PPy2FqghZu78"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}