{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline for Subliminal Steering\n",
    "\n",
    "Interactive notebook for preparing Data-1 (HuggingFace) and Data-2 (Model-2 generation) following Plan.md requirements.\n",
    "\n",
    "This notebook provides step-by-step data preparation with visualization and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('.')\n",
    "\n",
    "from prepare_data import DataPipeline\n",
    "from utils_io import setup_device, log_gpu_memory\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up experimental parameters following Plan.md specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental configuration\n",
    "CONFIG = {\n",
    "    'model_name': 'Qwen/Qwen2.5-7B-Instruct',\n",
    "    'hf_dataset_name': 'minhxle/subliminal-learning_numbers_dataset',\n",
    "    'hf_config': 'qwen2.5-7b-instruct_bear_preference',\n",
    "    'output_dir': './notebook_data_output',\n",
    "    'num_samples': 1000,  # Reduced for notebook demonstration\n",
    "    'force_cpu': False,  # Set to True if no GPU\n",
    "    'low_memory': True   # Enable memory optimizations\n",
    "}\n",
    "\n",
    "print(\"Data Pipeline Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Check device availability\n",
    "device = setup_device(CONFIG['force_cpu'])\n",
    "log_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize Data Pipeline\n",
    "\n",
    "Create the data pipeline with resource-aware configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data pipeline\n",
    "pipeline = DataPipeline(\n",
    "    model_name=CONFIG['model_name'],\n",
    "    hf_dataset_name=CONFIG['hf_dataset_name'],\n",
    "    hf_config=CONFIG['hf_config'],\n",
    "    output_dir=CONFIG['output_dir'],\n",
    "    force_cpu=CONFIG['force_cpu'],\n",
    "    low_memory=CONFIG['low_memory']\n",
    ")\n",
    "\n",
    "print(\"Data pipeline initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Data-1 from HuggingFace\n",
    "\n",
    "Load the subliminal learning dataset containing bear-preference numeric sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data-1 from HuggingFace\n",
    "print(\"Loading Data-1 from HuggingFace...\")\n",
    "data1_dataset = pipeline.load_data1_from_hf(max_samples=CONFIG['num_samples'])\n",
    "\n",
    "# Extract sequences for analysis\n",
    "data1_sequences = [example['text'] for example in data1_dataset]\n",
    "\n",
    "print(f\"\\nLoaded {len(data1_sequences)} Data-1 sequences\")\n",
    "print(\"\\nFirst 5 examples:\")\n",
    "for i, seq in enumerate(data1_sequences[:5]):\n",
    "    print(f\"  {i+1}: {seq[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Analyze Data-1 Properties\n",
    "\n",
    "Examine the structure and properties of the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Data-1 properties\n",
    "tokenizer = pipeline.tokenizer\n",
    "\n",
    "# Tokenize sequences to analyze lengths\n",
    "tokenized_sequences = [tokenizer(seq, add_special_tokens=False)['input_ids'] \n",
    "                      for seq in data1_sequences]\n",
    "sequence_lengths = [len(tokens) for tokens in tokenized_sequences]\n",
    "\n",
    "# Create length distribution plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Length histogram\n",
    "axes[0].hist(sequence_lengths, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Sequence Length (tokens)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Data-1 Sequence Length Distribution')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Length statistics\n",
    "length_stats = {\n",
    "    'Min': min(sequence_lengths),\n",
    "    'Max': max(sequence_lengths), \n",
    "    'Mean': np.mean(sequence_lengths),\n",
    "    'Median': np.median(sequence_lengths),\n",
    "    'Std': np.std(sequence_lengths)\n",
    "}\n",
    "\n",
    "# Bar plot of statistics\n",
    "axes[1].bar(length_stats.keys(), length_stats.values(), color='lightcoral', alpha=0.7)\n",
    "axes[1].set_ylabel('Tokens')\n",
    "axes[1].set_title('Data-1 Length Statistics')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Data-1 Analysis:\")\n",
    "for stat, value in length_stats.items():\n",
    "    print(f\"  {stat}: {value:.2f} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate Data-2 from Model-2\n",
    "\n",
    "Generate neutral numeric sequences using the base model without trait preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data-2 from Model-2\n",
    "print(\"Generating Data-2 from Model-2 (this may take several minutes)...\")\n",
    "print(\"Using resource-aware generation with sharding...\")\n",
    "\n",
    "data2_sequences = pipeline.generate_data2_from_model2(\n",
    "    data1_dataset,\n",
    "    num_samples=len(data1_sequences),\n",
    "    batch_size=2,  # Small batch for memory efficiency\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(data2_sequences)} Data-2 sequences\")\n",
    "print(\"\\nFirst 5 examples:\")\n",
    "for i, seq in enumerate(data2_sequences[:5]):\n",
    "    print(f\"  {i+1}: {seq[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Compare Data-1 vs Data-2\n",
    "\n",
    "Analyze differences between trait-bearing and neutral sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Data-1 vs Data-2\n",
    "data2_tokenized = [tokenizer(seq, add_special_tokens=False)['input_ids'] \n",
    "                  for seq in data2_sequences]\n",
    "data2_lengths = [len(tokens) for tokens in data2_tokenized]\n",
    "\n",
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Length comparison histogram\n",
    "axes[0,0].hist([sequence_lengths, data2_lengths], bins=20, alpha=0.7, \n",
    "               label=['Data-1 (trait)', 'Data-2 (neutral)'], color=['skyblue', 'lightcoral'])\n",
    "axes[0,0].set_xlabel('Sequence Length (tokens)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].set_title('Sequence Length Comparison')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Length box plots\n",
    "axes[0,1].boxplot([sequence_lengths, data2_lengths], labels=['Data-1', 'Data-2'])\n",
    "axes[0,1].set_ylabel('Sequence Length (tokens)')\n",
    "axes[0,1].set_title('Length Distribution Comparison')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Sample comparison table\n",
    "comparison_data = []\n",
    "for i in range(min(10, len(data1_sequences), len(data2_sequences))):\n",
    "    comparison_data.append({\n",
    "        'Index': i+1,\n",
    "        'Data-1 Length': len(tokenized_sequences[i]),\n",
    "        'Data-2 Length': len(data2_tokenized[i]),\n",
    "        'Data-1 Preview': data1_sequences[i][:30] + '...',\n",
    "        'Data-2 Preview': data2_sequences[i][:30] + '...'\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Display statistics\n",
    "stats_comparison = pd.DataFrame({\n",
    "    'Data-1': [np.mean(sequence_lengths), np.std(sequence_lengths), \n",
    "              min(sequence_lengths), max(sequence_lengths)],\n",
    "    'Data-2': [np.mean(data2_lengths), np.std(data2_lengths),\n",
    "              min(data2_lengths), max(data2_lengths)]\n",
    "}, index=['Mean', 'Std', 'Min', 'Max'])\n",
    "\n",
    "# Plot statistics comparison\n",
    "stats_comparison.plot(kind='bar', ax=axes[1,0], color=['skyblue', 'lightcoral'], alpha=0.7)\n",
    "axes[1,0].set_title('Statistical Comparison')\n",
    "axes[1,0].set_ylabel('Tokens')\n",
    "axes[1,0].tick_params(axis='x', rotation=0)\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Length difference scatter\n",
    "length_diffs = [abs(l1 - l2) for l1, l2 in zip(sequence_lengths, data2_lengths)]\n",
    "axes[1,1].scatter(range(len(length_diffs)), length_diffs, alpha=0.6, color='green')\n",
    "axes[1,1].set_xlabel('Sequence Index')\n",
    "axes[1,1].set_ylabel('Length Difference (tokens)')\n",
    "axes[1,1].set_title('Pairwise Length Differences')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nData Comparison Summary:\")\n",
    "print(stats_comparison)\n",
    "print(f\"\\nMean length difference: {np.mean(length_diffs):.2f} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Sequence Alignment\n",
    "\n",
    "Apply right-padding alignment as required by Plan.md for position consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sequence alignment\n",
    "print(\"Applying right-padding alignment...\")\n",
    "aligned_data1, aligned_data2 = pipeline.align_sequences(data1_sequences, data2_sequences)\n",
    "\n",
    "# Verify alignment\n",
    "aligned_lengths_1 = [len(tokenizer(seq, add_special_tokens=False)['input_ids']) \n",
    "                    for seq in aligned_data1]\n",
    "aligned_lengths_2 = [len(tokenizer(seq, add_special_tokens=False)['input_ids']) \n",
    "                    for seq in aligned_data2]\n",
    "\n",
    "print(f\"\\nAlignment Results:\")\n",
    "print(f\"  Data-1 aligned sequences: {len(aligned_data1)}\")\n",
    "print(f\"  Data-2 aligned sequences: {len(aligned_data2)}\")\n",
    "print(f\"  Data-1 length range: {min(aligned_lengths_1)} - {max(aligned_lengths_1)}\")\n",
    "print(f\"  Data-2 length range: {min(aligned_lengths_2)} - {max(aligned_lengths_2)}\")\n",
    "\n",
    "# Verify perfect alignment\n",
    "alignment_perfect = all(l1 == l2 for l1, l2 in zip(aligned_lengths_1, aligned_lengths_2))\n",
    "print(f\"  Perfect alignment achieved: {alignment_perfect}\")\n",
    "\n",
    "# Show alignment examples\n",
    "print(\"\\nAlignment Examples:\")\n",
    "for i in range(3):\n",
    "    print(f\"  Pair {i+1}:\")\n",
    "    print(f\"    Data-1: {aligned_data1[i][:80]}...\")\n",
    "    print(f\"    Data-2: {aligned_data2[i][:80]}...\")\n",
    "    print(f\"    Lengths: {aligned_lengths_1[i]} vs {aligned_lengths_2[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Data Validation\n",
    "\n",
    "Validate that all sequences meet numeric-only requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate numeric sequences\n",
    "from utils_io import validate_numeric_sequence\n",
    "\n",
    "# Check Data-1 validation\n",
    "data1_valid = [validate_numeric_sequence(seq) for seq in aligned_data1]\n",
    "data1_valid_count = sum(data1_valid)\n",
    "\n",
    "# Check Data-2 validation\n",
    "data2_valid = [validate_numeric_sequence(seq) for seq in aligned_data2]\n",
    "data2_valid_count = sum(data2_valid)\n",
    "\n",
    "print(\"Data Validation Results:\")\n",
    "print(f\"  Data-1 valid sequences: {data1_valid_count}/{len(aligned_data1)} ({data1_valid_count/len(aligned_data1)*100:.1f}%)\")\n",
    "print(f\"  Data-2 valid sequences: {data2_valid_count}/{len(aligned_data2)} ({data2_valid_count/len(aligned_data2)*100:.1f}%)\")\n",
    "\n",
    "# Show invalid examples if any\n",
    "invalid_data1 = [seq for seq, valid in zip(aligned_data1, data1_valid) if not valid]\n",
    "invalid_data2 = [seq for seq, valid in zip(aligned_data2, data2_valid) if not valid]\n",
    "\n",
    "if invalid_data1:\n",
    "    print(f\"\\nInvalid Data-1 examples ({len(invalid_data1)}):\")\n",
    "    for seq in invalid_data1[:3]:\n",
    "        print(f\"  '{seq[:60]}...'\")\n",
    "\n",
    "if invalid_data2:\n",
    "    print(f\"\\nInvalid Data-2 examples ({len(invalid_data2)}):\")\n",
    "    for seq in invalid_data2[:3]:\n",
    "        print(f\"  '{seq[:60]}...'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save Prepared Dataset\n",
    "\n",
    "Save the complete aligned dataset for use in steering vector construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final dataset structure\n",
    "final_dataset = {\n",
    "    'data1_sequences': aligned_data1,\n",
    "    'data2_sequences': aligned_data2,\n",
    "    'metadata': {\n",
    "        'model_name': CONFIG['model_name'],\n",
    "        'hf_dataset': CONFIG['hf_dataset_name'],\n",
    "        'hf_config': CONFIG['hf_config'],\n",
    "        'num_samples': len(aligned_data1),\n",
    "        'alignment_perfect': alignment_perfect,\n",
    "        'data1_valid_rate': data1_valid_count / len(aligned_data1),\n",
    "        'data2_valid_rate': data2_valid_count / len(aligned_data2),\n",
    "        'preparation_timestamp': pd.Timestamp.now().isoformat()\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save dataset\n",
    "from utils_io import save_results\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(CONFIG['output_dir'])\n",
    "save_results(final_dataset, output_dir, 'notebook_prepared_dataset')\n",
    "\n",
    "# Also save as CSV for easy inspection\n",
    "df_final = pd.DataFrame({\n",
    "    'data1': aligned_data1,\n",
    "    'data2': aligned_data2\n",
    "})\n",
    "df_final.to_csv(output_dir / 'prepared_sequences.csv', index=False)\n",
    "\n",
    "print(\"Dataset saved successfully!\")\n",
    "print(f\"  Location: {output_dir}\")\n",
    "print(f\"  Files: notebook_prepared_dataset.pkl, prepared_sequences.csv\")\n",
    "print(f\"  Total sequences: {len(aligned_data1)} Data-1, {len(aligned_data2)} Data-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Data preparation completed successfully following Plan.md requirements:\n",
    "\n",
    "✅ **Data-1**: Loaded from HuggingFace subliminal learning dataset  \n",
    "✅ **Data-2**: Generated from Model-2 using resource-aware processing  \n",
    "✅ **Numeric validation**: All sequences contain only numbers and commas  \n",
    "✅ **Right-padding alignment**: Sequences aligned for position consistency  \n",
    "✅ **Reproducible storage**: Dataset saved for steering vector construction  \n",
    "\n",
    "The prepared data is now ready for the next phase: steering vector construction using activation-difference methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary statistics\n",
    "summary_stats = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Total Data-1 sequences',\n",
    "        'Total Data-2 sequences', \n",
    "        'Sequences perfectly aligned',\n",
    "        'Data-1 validation rate',\n",
    "        'Data-2 validation rate',\n",
    "        'Average sequence length',\n",
    "        'Memory optimization used',\n",
    "        'CPU/GPU processing'\n",
    "    ],\n",
    "    'Value': [\n",
    "        len(aligned_data1),\n",
    "        len(aligned_data2),\n",
    "        'Yes' if alignment_perfect else 'No',\n",
    "        f\"{data1_valid_count/len(aligned_data1)*100:.1f}%\",\n",
    "        f\"{data2_valid_count/len(aligned_data2)*100:.1f}%\",\n",
    "        f\"{np.mean(aligned_lengths_1):.1f} tokens\",\n",
    "        'Yes' if CONFIG['low_memory'] else 'No',\n",
    "        'CPU' if CONFIG['force_cpu'] else 'GPU/Auto'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATA PREPARATION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(summary_stats.to_string(index=False))\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}